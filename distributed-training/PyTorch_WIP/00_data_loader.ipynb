{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97b684b6-eb52-4db7-b364-4a2262a4f6a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Natural Scenes Dataset (NSD) \n",
    "\n",
    "https://cvnlab.slite.page/p/CT9Fwl4_hc/NSD-Data-Manual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c0f6c63-2c4f-4fb6-ad85-3fd72bd2972d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install h5py fsspec requests aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "746fa2cf-e3c0-479f-b055-8400d127aacd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## STIMULI\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path = 'https://natural-scenes-dataset.s3.amazonaws.com/nsddata/ppdata/subj01/behav/responses.tsv'\n",
    "target_df = pd.read_csv(path,\n",
    "                 delimiter='\\t')\n",
    "# can the brain activity predict decision correctness (i.e. was it a recent image?)? target ==> ISCORRECT\n",
    "# can the brain activity predict image (i.e. was it a seen image from whole session?)? target ==> ISOLD \n",
    "# can the brain activity predict image from current session (i.e. was it a seen image from current session?)? target ==> ISOLDCURRENT\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfa11078-8561-4262-9871-022f2520071a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import fsspec\n",
    "\n",
    "URL = 'https://natural-scenes-dataset.s3.amazonaws.com/nsddata_betas/ppdata/subj01/func1mm/betas_fithrf_GLMdenoise_RR/betas_session01.hdf5' # Assuming a publicly accessible url\n",
    "\n",
    "remote_f = fsspec.open(URL, mode=\"rb\")\n",
    "if hasattr(remote_f, \"open\"):\n",
    "    remote_f = remote_f.open()\n",
    "\n",
    "f = h5py.File(remote_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d7fb0da-68b5-4931-a467-b2f9e8ab95a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "f['betas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "083fa83b-b17f-4d0d-bf7e-804c05a193e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trial = 20\n",
    "stack = 85\n",
    "# trial, stack, y, x\n",
    "# We divide by 300 to get it in percent signal change. Original data is multipled by 300 to ensure data has high enough dynamic range to cover. \n",
    "# get the fMRI signals for a single stack across all the trials.\n",
    "img = f['betas'][:, stack, :, :].astype('float32')/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a9c232a-6420-4484-a457-214811599247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cmapsign4 = np.array([\n",
    "  [.8, 1, 1], # cyan-white\n",
    "  [0, 1, 1],  # cyan\n",
    "  [0, 0, 1],  # blue\n",
    "  [0, 0, 0],  # black\n",
    "  [1, 0, 0],  # red\n",
    "  [1, 1, 0],  # yellow\n",
    "  [1, 1, .8], # yellow-white\n",
    "  ])\n",
    "custom_cmap = ListedColormap(cmapsign4)\n",
    "p1, p99 = np.percentile(img.mean(axis=0), [1, 99])\n",
    "\n",
    "rotated_img = np.rot90(img.mean(axis=0))\n",
    "plt.imshow(rotated_img, cmap=custom_cmap, vmin=-p99, vmax=p99)\n",
    "plt.colorbar() # Display the image with Berlin colormap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c76c65a1-e764-4f99-b97e-aaee9a744494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ETL images all into a Delta Table.\n",
    "We recommend to paths when working with image datasets in Databricks:\n",
    "1. Create a Delta Table with the image stashed directly into the table. This is the preferred route for smaller images (e.g. single channel)\n",
    "2. Stash the images into Databricks Volumes and then create a Delta Table that has a pointer to each image. \n",
    "\n",
    "Since our images are single-channel (i.e. percent change) and 186x145px for 1mm resolution or 104x81 for 1.8mm resolution, we will follow option 1 and stash the image directly into a Delta Table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a86316f-787e-45a4-af9f-d49b92188b58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SUBJECT = '01' #01:08\n",
    "SESSION = '01' #01:37\n",
    "RESOLUTION = \"1mm\" #can be '1mm' or '1pt8mm'\n",
    "\n",
    "# Natural Scenes Dataset (NSD) publicly accessible URL for fMRI images \n",
    "response_url = f'https://natural-scenes-dataset.s3.amazonaws.com/nsddata_betas/ppdata/subj{SUBJECT}/func{RESOLUTION}/betas_fithrf_GLMdenoise_RR/betas_session{SESSION}.hdf5' \n",
    "behavioral_url = f'https://natural-scenes-dataset.s3.amazonaws.com/nsddata/ppdata/subj{SUBJECT}/behav/responses.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33ae2872-6821-4c6d-8b60-3fcf636dbe67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Open behavior TSV file\n",
    "behavioral_df = pd.read_csv(behavioral_url, delimiter='\\t')\n",
    "\n",
    "# Open fMRI hdf5 file\n",
    "remote_f = fsspec.open(URL, mode=\"rb\")\n",
    "if hasattr(remote_f, \"open\"):\n",
    "    remote_f = remote_f.open()\n",
    "\n",
    "response_dict = h5py.File(remote_f)['betas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2acb83c0-835e-46a4-a5fc-ad01a2f62c8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b80d5eb9-593f-40ce-b06a-448fc3b6937c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Get behavioral data for this specific session\n",
    "session_behavioral_df = behavioral_df.loc[(behavioral_df['SESSION'] == int(SESSION))].reset_index(drop=True)\n",
    "\n",
    "num_trials = response_dict.shape[0]\n",
    "num_stacks = response_dict.shape[1]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for trial in range(0, num_trials):\n",
    "  for stack in range(0, num_stacks):\n",
    "    print(trial, stack)\n",
    "    # We divide by 300 to get it in percent signal change. Original data is multipled by 300 to ensure data has high enough dynamic range to cover. \n",
    "    img = response_dict[trial, stack, :, :].astype('float32')/300\n",
    "    \n",
    "    # data to append\n",
    "    write = session_behavioral_df.iloc[trial]\n",
    "    write['IMAGE_SLICE'] = stack\n",
    "    write['IMAGE'] = img\n",
    "    write = pd.DataFrame(write).transpose()\n",
    "\n",
    "    final_df = pd.concat([final_df, write])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2ff0aab-3b1e-4f13-844f-bcec62552120",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "372652b1-c16b-415e-9877-ab60607863d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "00_data_loader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
