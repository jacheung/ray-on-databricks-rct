{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa1a007e-887d-4cdf-a68a-4ccee4587eee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ray Data + Ray Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "832e54d9-7bc3-4b9c-aecb-8f117ed329a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install ray[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b92f84cd-0414-4ccc-9c40-fe21e9db82d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Original Code here:\n",
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "ray.shutdown()\n",
    "import argparse\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from filelock import FileLock\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "# from ray.tune import Checkpoint\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 512\n",
    "TEST_SIZE = 256\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def train_func(model, optimizer, train_loader, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test_func(model, data_loader, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size=64):\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "    # We add FileLock here because multiple workers will want to\n",
    "    # download data, and this may cause overwrites since\n",
    "    # DataLoader is not threadsafe.\n",
    "    with FileLock(os.path.expanduser(\"~/data.lock\")):\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                \"~/data\", train=True, download=True, transform=mnist_transforms\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                \"~/data\", train=False, download=True, transform=mnist_transforms\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train_mnist(config):\n",
    "    should_checkpoint = config.get(\"should_checkpoint\", False)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    train_loader, test_loader = get_data_loaders()\n",
    "    model = ConvNet().to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"]\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        train_func(model, optimizer, train_loader, device)\n",
    "        acc = test_func(model, test_loader, device)\n",
    "        metrics = {\"mean_accuracy\": acc}\n",
    "\n",
    "        # Report metrics (and possibly a checkpoint)\n",
    "        if should_checkpoint:\n",
    "            with tempfile.TemporaryDirectory() as tempdir:\n",
    "                torch.save(model.state_dict(), os.path.join(tempdir, \"model.pt\"))\n",
    "                # tune.report(metrics, checkpoint=Checkpoint.from_directory(tempdir))\n",
    "        else:\n",
    "            tune.report(metrics)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"PyTorch MNIST Example\")\n",
    "    parser.add_argument(\n",
    "        \"--cuda\", action=\"store_true\", default=False, help=\"Enables GPU training\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--smoke-test\", action=\"store_true\", help=\"Finish quickly for testing\"\n",
    "    )\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    ray.init(num_cpus=2 if args.smoke_test else None)\n",
    "\n",
    "    # for early stopping\n",
    "    sched = AsyncHyperBandScheduler()\n",
    "\n",
    "    resources_per_trial = {\"cpu\": 2, \"gpu\": int(args.cuda)}  # set this for GPUs\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_mnist, resources=resources_per_trial),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"mean_accuracy\",\n",
    "            mode=\"max\",\n",
    "            scheduler=sched,\n",
    "            num_samples=1 if args.smoke_test else 50,\n",
    "        ),\n",
    "        run_config=ray.train.RunConfig(\n",
    "            name=\"exp\",\n",
    "            stop={\n",
    "                \"mean_accuracy\": 0.98,\n",
    "                \"training_iteration\": 5 if args.smoke_test else 100,\n",
    "            },\n",
    "        ),\n",
    "        param_space={\n",
    "            \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"momentum\": tune.uniform(0.1, 0.9),\n",
    "        },\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "\n",
    "    print(\"Best config is:\", results.get_best_result().config)\n",
    "\n",
    "    assert not results.errors"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "distributed_pytorch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
