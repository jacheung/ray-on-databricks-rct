{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0c63aaf-35c5-45c3-a031-89cb5bf4d898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Parallelized Prophet Modeling with Ray\n",
    "\n",
    "Prophet is a simple, yet powerful, additive forecasting model. To the former, it's implementation is intuitive and requires editing a few parameters and, to the latter, it provides an algorithmically efficient way to identify time-related patterns in the data. These two aspects make Prophet an ideal starting, and possibly end, point for a forecasting model. \n",
    "\n",
    "However, in real-world production use-cases we must overcome scaling challenges in model training and inference. Specifically, in retail use-cases we'd like to generate forecasting models for every combination of store x SKU. This can lead to 100K+ models. Furthermore, business demands may require all these models be trained and inferenced within short time frames.\n",
    "\n",
    "In this specific notebook, we will use Ray Data and map groups to parallelize training across the Ray cluster. At the same time, we'll use Spark for efficient data loading + writing the results back to Delta. \n",
    "\n",
    "For compute you simply need 5 worker nodes (`m5.4xlarge` which has 16 CPU and 64GiB memory) without any special configurations.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"num_workers\": 5,\n",
    "    \"cluster_name\": \"Multi Node MLR\",\n",
    "    \"spark_version\": \"16.4.x-cpu-ml-scala2.13\",\n",
    "    \"aws_attributes\": {\n",
    "        \"first_on_demand\": 1,\n",
    "        \"availability\": \"SPOT_WITH_FALLBACK\",\n",
    "        \"zone_id\": \"auto\",\n",
    "        \"spot_bid_price_percent\": 100,\n",
    "        \"ebs_volume_type\": \"GENERAL_PURPOSE_SSD\",\n",
    "        \"ebs_volume_count\": 1,\n",
    "        \"ebs_volume_size\": 100\n",
    "    },\n",
    "    \"node_type_id\": \"m5.4xlarge\",\n",
    "    \"driver_node_type_id\": \"m5.4xlarge\",\n",
    "    \"autotermination_minutes\": 45,\n",
    "    \"enable_elastic_disk\": true,\n",
    "    \"single_user_name\": \"jon.cheung@databricks.com\",\n",
    "    \"enable_local_disk_encryption\": false,\n",
    "    \"data_security_mode\": \"SINGLE_USER\",\n",
    "    \"runtime_engine\": \"STANDARD\",\n",
    "    \"assigned_principal\": \"user:jon.cheung@databricks.com\",\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19042c4f-f4d5-4e17-8030-cdce13849787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qU ray[all]=2.47.1\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "648b7a92-5225-4115-8521-df6cc892bbae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = \"main\"\n",
    "schema_name = \"ray_gtm_examples\"\n",
    "data_table = \"data_synthetic_timeseries_10000_groups\"\n",
    "write_table = \"prophet_inference_10000_groups\"\n",
    "label=\"y\"\n",
    "\n",
    "# This is for stashing the cluster logs\n",
    "ray_logs_path = \"/dbfs/Users/jon.cheung@databricks.com/ray_collected_logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "619cb71f-f3f8-4b48-87cc-9c4050665b5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Optional: Generate a massive time-series dataset\n",
    "\n",
    "Default is 10k groups x 50k datapoints per group. Edit within the 00_generate_timeseries_data notebook\n",
    "This may take 15 mins or so to generate all the data and save. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ba0d28a-03b7-428d-ab0e-bc7babf504da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00-generate-timeseries-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccf949cc-893d-4248-bc63-e49bf38b78c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Synthetic data generation \n",
    "if not spark.catalog.tableExists(f\"{catalog_name}.{schema_name}.{data_table}\"): \n",
    "  # Create table for features\n",
    "  id_sdf.write.mode('overwrite').saveAsTable(f\"{catalog_name}.{schema_name}.{data_table}\")\n",
    "  print(f\"... OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfc4378b-3c77-436d-9955-dc202085a6bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ray Data with `map_groups`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14052039-5490-4495-9dbf-35a4319b8f90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.util.spark import setup_ray_cluster, shutdown_ray_cluster\n",
    "\n",
    "restart = True\n",
    "if restart is True:\n",
    "  try:\n",
    "    shutdown_ray_cluster()\n",
    "  except:\n",
    "    pass\n",
    "  try:\n",
    "    ray.shutdown()\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "# This notebook will use a hybrid Ray + Spark cluster. Spark for data handling (i.e. read/write) and Ray for task parallelism (i.e. ML training). \n",
    "# Since I have 5 worker nodes, I'll set 3 workers for the Ray cluster, leaving 2 for Spark. \n",
    "setup_ray_cluster(\n",
    "  min_worker_nodes=3,\n",
    "  max_worker_nodes=3,\n",
    "  num_cpus_worker_node=16,\n",
    "  num_gpus_worker_node=0,\n",
    "  num_cpus_head_node=16, \n",
    "  collect_log_to_path=ray_logs_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95c8549b-83a6-40cd-aec6-b329c19a1b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "def train_and_inference_prophet(grouped_data: pd.DataFrame, horizon: int):\n",
    "    \"\"\"\n",
    "    Trains a Prophet model on grouped time series data and generates future forecasts.\n",
    "\n",
    "    This function is designed to be applied to a Ray dataset using `map_groups`.\n",
    "    It expects the input DataFrame to have 'ds' (datestamp), 'y' (target variable),\n",
    "    and 'group_name' columns.\n",
    "\n",
    "    Args:\n",
    "        grouped_data (pd.DataFrame): A DataFrame containing the time series data\n",
    "                                     for a specific group. It must have 'ds', 'y',\n",
    "                                     and 'group_name' columns.\n",
    "        horizon (int): The number of future periods to forecast.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the forecasted data for the specified\n",
    "                      horizon, including the 'ds' (converted to string) and 'group_name'\n",
    "                      columns.\n",
    "    \"\"\"\n",
    "    # Extract the group name from the first row of the grouped data\n",
    "    group_name = grouped_data.loc[0, 'group_name']\n",
    "\n",
    "    # Initialize and fit the Prophet model\n",
    "    m = Prophet(daily_seasonality=True)\n",
    "    m.fit(grouped_data)\n",
    "\n",
    "    # Create a dataframe for future dates and generate forecasts\n",
    "    future = m.make_future_dataframe(periods=horizon)\n",
    "    forecast = m.predict(future)\n",
    "    \n",
    "    # Extract the forecasted data for the specified horizon\n",
    "    to_write = forecast.iloc[-horizon:]\n",
    "    to_write['ds'] = to_write['ds'].astype(str)  # Convert date to string for Spark writes back to Delta\n",
    "    to_write['group_name'] = group_name  # Add group name to the forecasted data\n",
    "\n",
    "    return to_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88304312-048e-4321-8938-3205a2c532a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import catalog\n",
    "from databricks.sdk.errors import ResourceAlreadyExists\n",
    "\n",
    "# Create Volumes path for Ray Data to store the data shards when converting from Spark --> Ray Data.\n",
    "# This path is also used when writing back to a Spark table from Ray Data. \n",
    "\n",
    "w = WorkspaceClient()\n",
    "ray_fuse_temp_directory = f'/Volumes/{catalog_name}/{schema_name}/ray_data_tmp_dir/'\n",
    "\n",
    "try:\n",
    "    created_volume = w.volumes.create(catalog_name=catalog_name,\n",
    "                                        schema_name=schema_name,\n",
    "                                        name='ray_data_tmp_dir',\n",
    "                                        volume_type=catalog.VolumeType.MANAGED\n",
    "                                        )\n",
    "    print(f\"Volume {ray_fuse_temp_directory} created successfully\")\n",
    "except ResourceAlreadyExists:\n",
    "    print(f\"Volume {ray_fuse_temp_directory} already exists. Skipping volumes creation.\")\n",
    "\n",
    "os.environ['RAY_UC_VOLUMES_FUSE_TEMP_DIR']=ray_fuse_temp_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88fd8775-6bf3-4053-b16e-7210714c4851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "# Since we are using a hybrid cluster, we are going to read data using Spark and then convert to Ray. \n",
    "# Note that this is an in-memory operation and requires using a non-autoscaling cluster.\n",
    "sdf = spark.read.table(f\"{catalog_name}.{schema_name}.{data_table}\")\n",
    "ray_data = ray.data.from_spark(sdf)\n",
    "\n",
    "# Consider using ray.data.read_delta_sharing_tables() for memory efficient load compared to from_spark (i.e. no need to do in-memory Spark -> Ray Data)\n",
    "\n",
    "# Group data by group_name and apply the train_and_inference_prophet function to each group. \n",
    "# Note that we are using 1 CPU per group to train a Prophet model.\n",
    "grouped = ray_data.groupby(\"group_name\")\n",
    "results = grouped.map_groups(train_and_inference_prophet, \n",
    "                             fn_kwargs={\"horizon\": 14}, \n",
    "                             num_cpus=1)\n",
    "\n",
    "# Write grouped results to Databricks Unity Catalog. \n",
    "ray.data.Dataset.write_databricks_table(results, \n",
    "                                        f\"{catalog_name}.{schema_name}.{write_table}\",\n",
    "                                         mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1436459421794120,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "01-parallelized-prophet-forecasting",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
